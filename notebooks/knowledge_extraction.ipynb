{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4bf3a88-2a98-4324-92ff-896344ff2f4c",
   "metadata": {},
   "source": [
    "# Knowledge extraction from text\n",
    "\n",
    "Erik Tjong Kim Sang\n",
    "\n",
    "e.tjongkimsang(a)esciencecenter.nl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6262acf-2f98-481c-9f16-1bef6fb5c433",
   "metadata": {},
   "source": [
    "Python package requirements:\n",
    "* regex\n",
    "* nltk\n",
    "* transformers\n",
    "* pytorch\n",
    "* rdflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92b3a3f-84e9-4fbf-b817-74d13aa40562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324d8420-b042-4b38-bf0e-c016c72db4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeal(text=None):\n",
    "    clear_output(wait=True)\n",
    "    if not text is None: \n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59748f36-8d9a-47c6-ac73-2fb84b7f3619",
   "metadata": {},
   "source": [
    "## 1. Get texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb24947-c4c0-4e51-8a26-1834cdca9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7f469-1cdb-47bb-a511-72a75ab32780",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = \"https://gutenberg.org/cache/epub/2591/pg2591.txt\"\n",
    "LAST_PREAMBLE_LINE = \"THE BROTHERS GRIMM FAIRY TALES\"\n",
    "FIRST_POSTCRIPT_LINE = \"*****\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f19c7-b4ca-49df-980c-14018ac5a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bytes_to_string(string):\n",
    "    return string.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b9c65-8fe6-4b29-9d46-5ef391da523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_url(data_url):\n",
    "    with urllib.request.urlopen(data_url) as response:\n",
    "        data_text = response.read()\n",
    "        response.close()\n",
    "    return convert_bytes_to_string(data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc73ec-773a-48b2-be99-ec3f3de137a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stories_from_text(data_text, \n",
    "                          last_preamble_line=LAST_PREAMBLE_LINE,\n",
    "                          first_postscript_line=FIRST_POSTCRIPT_LINE):\n",
    "    in_text = False\n",
    "    texts = {}\n",
    "    texts_key = \"\"\n",
    "    for line in data_text.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        if line == last_preamble_line:\n",
    "            in_text = True\n",
    "        elif line == first_postscript_line:\n",
    "            in_text = False\n",
    "        elif in_text:\n",
    "            if regex.search(\"^[A-Z, -]+$\", line.strip().split(\"[\")[0]):\n",
    "                texts_key = line\n",
    "                texts[texts_key] = \"\"\n",
    "            elif len(texts) > 0:\n",
    "                texts[texts_key] += line + \" \"\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcf8782-9511-499a-b032-e72dd5166df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = get_text_from_url(DATA_URL)\n",
    "texts = get_stories_from_text(data_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665e251f-d54f-4f43-88c1-5f7b3838bbe9",
   "metadata": {},
   "source": [
    "## 2. Extract relation triples from texts\n",
    "\n",
    "Uses the system [REBEL](https://github.com/Babelscape/rebel), based on blog by Fabio Chiusano: https://medium.com/nlplanet/building-a-knowledge-base-from-texts-a-full-practical-example-8dbbffb912fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3dbf6e-a1ae-41f0-be4b-1a2cf623e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd03f42-b56f-4fa8-919b-9482ec4b6428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relations_from_model_output(text):\n",
    "    relations = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    text_replaced = text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\")\n",
    "    for token in text_replaced.split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                relations.append({\n",
    "                    'head': subject.strip(),\n",
    "                    'type': relation.strip(),\n",
    "                    'tail': object_.strip()\n",
    "                })\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                relations.append({\n",
    "                    'head': subject.strip(),\n",
    "                    'type': relation.strip(),\n",
    "                    'tail': object_.strip()\n",
    "                })\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        relations.append({\n",
    "            'head': subject.strip(),\n",
    "            'type': relation.strip(),\n",
    "            'tail': object_.strip()\n",
    "        })\n",
    "    return relations\n",
    "\n",
    "# https://gist.githubusercontent.com/fabiochiusano/934ad5ff318626befbdd20c72e074186/raw/e3e44110a0db5408d17fba52be559ecaf676b6d2/kb_4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcc3e1a-9ff1-4fae-998b-2bc83f634f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KB():\n",
    "    def __init__(self):\n",
    "        self.relations = []\n",
    "\n",
    "    def are_relations_equal(self, r1, r2):\n",
    "        return all(r1[attr] == r2[attr] for attr in [\"head\", \"type\", \"tail\"])\n",
    "\n",
    "    def exists_relation(self, r1):\n",
    "        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)\n",
    "\n",
    "    def add_relation(self, r):\n",
    "        if not self.exists_relation(r):\n",
    "            self.relations.append(r)\n",
    "\n",
    "    def print(self):\n",
    "        print(\"Relations:\")\n",
    "        for r in self.relations:\n",
    "            print(f\"  {r}\")\n",
    "\n",
    "# source: https://gist.githubusercontent.com/fabiochiusano/e64d5250371e18f7a6cc02ac0cdc64c5/raw/24af0f7f23b313591fe91fc9f8826cf216ca4568/kb_5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f972f-8f84-4ea1-a9a4-6b19f7f44f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_small_text_to_kb(text, verbose=False, prefix=\"\"):\n",
    "    kb = KB()\n",
    "\n",
    "    # Tokenizer text\n",
    "    model_inputs = tokenizer(text, max_length=512, padding=True, truncation=True,\n",
    "                            return_tensors='pt')\n",
    "    if verbose:\n",
    "        squeal(f\"{prefix}Num tokens: {len(model_inputs['input_ids'][0])}\")\n",
    "\n",
    "    # Generate\n",
    "    gen_kwargs = {\n",
    "        \"max_length\": 216,\n",
    "        \"length_penalty\": 0,\n",
    "        \"num_beams\": 5,\n",
    "        \"num_return_sequences\": 5\n",
    "    }\n",
    "    generated_tokens = model.generate(\n",
    "        **model_inputs,\n",
    "        **gen_kwargs,\n",
    "    )\n",
    "    decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n",
    "\n",
    "    # create kb\n",
    "    for sentence_pred in decoded_preds:\n",
    "        relations = extract_relations_from_model_output(sentence_pred)\n",
    "        for r in relations:\n",
    "            if regex.search(r[\"head\"], text): # block hallucinations\n",
    "                kb.add_relation(r)\n",
    "\n",
    "    return kb\n",
    "\n",
    "# source: https://gist.githubusercontent.com/fabiochiusano/ceec4d9ff1ce2ad25c40fbd8412aa9e4/raw/796771f88776fca9d7c4c84bd1b3a52d9ef5b5c1/kb_6.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ca975-4547-4cc0-acfe-7f07ad9745de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relations_per_text(text):\n",
    "    relations = []\n",
    "    sentences = sent_tokenize(text)\n",
    "    for sentence_index, sentence in enumerate(sentences):\n",
    "        clear_output(wait=True)\n",
    "        prefix = f\"sentence {1+sentence_index}/{len(sentences)} \"\n",
    "        kb = from_small_text_to_kb(sentence, verbose=True, prefix=prefix)\n",
    "        relations.extend(kb.__dict__[\"relations\"])\n",
    "    return relations\n",
    "\n",
    "# source for line 6: https://gist.githubusercontent.com/fabiochiusano/a720da218ee8d19de3130fa36c23a69b/raw/a9b94a3ddbad61cfb3713234476423fffbfdca41/kb_7.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8c93d8-522b-4899-9d7d-b6066aae017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af5b97-fa9f-472e-bc8f-7944fa20b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = extract_relations_per_text(texts[\"LITTLE RED-CAP [LITTLE RED RIDING HOOD]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d1f79e-08d5-4716-9e57-d368e9fbc0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb7e9b-6309-4fb8-adda-e7702da49b24",
   "metadata": {},
   "source": [
    "## 3. Lookup relation parts on Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297bcfa7-0f82-44bc-b074-cf606f9dc20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67344417-adf9-4886-ae83-7ec56947aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_cache = {}\n",
    "property_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aa3840-a86f-493a-afc1-a263ae2c5957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikidata_info(entity_name, cache=entity_cache, find_property=False):\n",
    "    if entity_name in cache:\n",
    "        return cache[entity_name]\n",
    "    url = f\"https://www.wikidata.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"wbsearchentities\",\n",
    "        \"format\": \"json\",\n",
    "        \"language\": \"en\",\n",
    "        \"limit\": 10,\n",
    "        \"uselang\": \"en\",\n",
    "        \"search\": entity_name\n",
    "    }\n",
    "    if find_property:\n",
    "        params[\"type\"] = \"property\"\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    if 'search' in data.keys():\n",
    "        cache[entity_name] = data[\"search\"]\n",
    "    else:\n",
    "        cache[entity_name] = []\n",
    "    return cache[entity_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0625eccb-de01-4a4a-8c91-a9bfd008d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for relation_index, relation in enumerate(relations):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"processing relation {relation_index + 1}/{len(relations)}\")\n",
    "    get_wikidata_info(relation[\"head\"])\n",
    "    get_wikidata_info(relation[\"type\"], cache=property_cache, find_property=True)\n",
    "    get_wikidata_info(relation[\"tail\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4f115-9cb7-45d4-aac4-4122d348de8c",
   "metadata": {},
   "source": [
    "## 4. Convert relation triples to RDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c402bc-2f20-4633-876f-2466a415b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287203a-1a36-44a0-8ca6-dec5cd9458b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = Namespace(\"http://www.wikidata.org/entity/\")\n",
    "wdt = Namespace(\"http://www.wikidata.org/prop/direct/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3101f533-88b4-46a0-96fa-a213f0fafe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_relations_in_knowledge_graph(relations):\n",
    "    knowledge_graph = Graph()\n",
    "    for relation in relations:\n",
    "        if (relation[\"head\"] in entity_cache and \n",
    "            relation[\"tail\"] in entity_cache and\n",
    "            relation[\"type\"] in property_cache and\n",
    "            len(entity_cache[relation[\"head\"]]) > 0 and \n",
    "            len(entity_cache[relation[\"tail\"]]) > 0 and\n",
    "            len(property_cache[relation[\"type\"]]) > 0):\n",
    "            head = wd[entity_cache[relation['head']][0]['id']]\n",
    "            type_ = wdt[property_cache[relation['type']][0]['id']]\n",
    "            tail = wd[entity_cache[relation['tail']][0]['id']]\n",
    "            knowledge_graph.add((URIRef(head), URIRef(type_), URIRef(tail)))\n",
    "    return knowledge_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ef34a-0606-4ce7-b58d-f798435f6384",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_graph = store_relations_in_knowledge_graph(relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380301e6-b6a8-4966-9f2e-af300d741a6e",
   "metadata": {},
   "source": [
    "## 5. Extract information from knowledge graph with SPARQL queries\n",
    "\n",
    "For tips on building SPARQL queries, see WikiData SPARQL tutorial: https://www.wikidata.org/wiki/Wikidata:SPARQL_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd9c986-f719-4ba6-92d6-30a422f797ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_property_id(property_label, cache=property_cache):\n",
    "    if property_label in property_cache and len(property_cache[property_label]) > 0:\n",
    "        return property_cache[property_label][0][\"id\"]\n",
    "    else:\n",
    "        raise ValueError(f\"unknown property label: {property_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614ad65-3458-4df8-9987-314eead9227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_prefix = \"http://www.wikidata.org/entity/\"\n",
    "search_cache = {}\n",
    "\n",
    "def get_entity_label(entity_url):\n",
    "    entity_id = entity_url.split(\"/\")[-1] \n",
    "    for entity_label in entity_cache:\n",
    "        for entity in entity_cache[entity_label]:\n",
    "            if url_prefix + entity[\"id\"] == entity_url:\n",
    "                return(entity[\"label\"])\n",
    "    return get_wikidata_info(entity_id, cache=search_cache)[0][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8f422b-479d-4af5-b520-a1a530c00c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_property_id(\"mother\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cf0ca6-5b85-48d5-a917-4035fb7ab136",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "\n",
    "SELECT ?head ?tail\n",
    "WHERE { \n",
    "    ?head wdt:P25 ?tail. \n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62ca05f-a4e3-4290-9688-a2039e05350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([(get_entity_label(str(relation[0])),\n",
    "               get_entity_label(str(relation[1])))\n",
    "              for relation in knowledge_graph.query(query)], columns=[\"head\", \"tail\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9159a533-6792-4de8-89b2-2c8a7ad3f87d",
   "metadata": {},
   "source": [
    "## 6. Visualize knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4fc1f4-5ab4-4b3f-988e-ae9062d964a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib.extras.external_graph_libs import rdflib_to_networkx_multidigraph\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e2892b-57cb-4bc7-99f0-eb6e047fe3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = rdflib_to_networkx_multidigraph(knowledge_graph)\n",
    "pos = nx.spring_layout(G, scale=2)\n",
    "edge_labels = nx.get_edge_attributes(G, 'r')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "nx.draw(G, with_labels=True, font_size=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd069f4-0cea-423e-9c34-6145bae02b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
